{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as lib\n",
    "\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from lime import lime_tabular\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import fairlearn.metrics as flm\n",
    "from fairlearn.reductions import DemographicParity, ExponentiatedGradient\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import selection_rate\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the FIM Bank\n",
    "\n",
    "At the FIM Bank we have different tiers of customers. People with an estimated income of more than 50k a year receive special treatment with superior products and better credit conditions. However, we keep struggling with our ranking policy. Some of our clients turned out to have lower incomes than expected which lead to severe losses. Other clientes complained about unfair treatment and accused our account managers of discrimination.\n",
    "\n",
    "## Current Process\n",
    "\n",
    "Our current process looks like this:\n",
    "* People apply for a credit and provide their data: demographics, education, occupation, income, financial history (e.g., Schufa-Auskunft).\n",
    "* A loan officer estimates the income of the applicant based on past experience and sympathy.\n",
    "* If the applicant is expected to earn more than 50k, he or she is granted superior status; otherwise, he or she is offered less favorable conditions.\n",
    "\n",
    "## Your Mission\n",
    "\n",
    "We need you to revise our ranking process. Therefore, you should design a ML model that selects the \"right\" clients for superior status. Develop a simple ML model that makes a binary decision about applicants' customer tiers, as depicted in this sketch. Positive means income >50k, negative means income <=50k.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; align-items: center;\">\n",
    "  <div style=\"display: flex; justify-content: center; align-items: center; padding: 10px; background-color: white;\">\n",
    "    <img src=\"img\\Classification.jpg\" style=\"max-height: 500px;\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "The ranking decision should fulfill three objectives. You will be confronted with several normative and economic tradeoff decisions along the way. **Please make notes about your tradeoff decisions or engage in a discussion with your colleagues.**\n",
    "\n",
    "### Business Objective\n",
    "**To maximize our profits you should correctly identify and select the clients that deserve superior conditions.**\n",
    "\n",
    "### Fairness Objective\n",
    "**At the same time, please make sure that everyone is treated fairly. It is up to you to determine what fair is - you can follow legal requirements, social norms, or academic insights. Just make sure to deliver it convincingly.**\n",
    "\n",
    "### Transparency Objective\n",
    "**The model should make justifiable decisions and allow for human supervision.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding: These are our clients\n",
    "Luckily, we gathered historical data on our clients' income. Here you find details about data collection and feature descriptions: https://archive.ics.uci.edu/dataset/2/adult\n",
    "* Familiarize yourself with the data at hand. \n",
    "* Take a look at the features and labels. \n",
    "* Plot some feature distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset with slight formal preprocessing\n",
    "dataset = (\n",
    "    pd.read_csv(\"Dataset.csv\", sep=';', encoding='ISO-8859-1')\n",
    "    .rename(columns={\"ï»¿Age\": \"age\"})\n",
    "    .drop(columns=[\"fnlwgt\", \"relationship\", \"education\"]) # drop redundant variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a glimpse into the dataset\n",
    "print(\"\\nThe dataset contains\", dataset.shape[0], \"data points and\", dataset.shape[1], \"features.\\n\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, standard deviation, min/max values, and quantiles of the numerical features\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the feature names you want to visualize\n",
    "feature_names = [\"age\", \"sex\", \"capital-gain\", \"race\"]\n",
    "lib.show_distribution(dataset, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "Before using our data to train a model, we need to some basic data preprocessing. Your decisions at this step might already change the outcome of your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"age\", \"workclass\", \"education-num\", \"marital-status\", \"occupation\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "# Generate a summary table of missing values for each column in the DataFrame.\n",
    "missing_values = lib.identify_missing_values(dataset, features)\n",
    "\n",
    "# Display a bar chart that shows the data availability for each feature\n",
    "msno.bar(dataset, color=\"dodgerblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy to handle missing values: mean\n",
    "missing_values_strategy = 'mean'\n",
    "\n",
    "# handle missing values based on the selected strategy\n",
    "dataset, features = lib.handle_missing_data(dataset, features, missing_values_strategy, missing_values)\n",
    "\n",
    "# Check if there are still any missing values in the entire DataFrame\n",
    "dataset.isnull().values.any()\n",
    "\n",
    "# Convert 'object' data types to 'float' if the column contains numeric values\n",
    "lib.transformObjectToFloat(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "To enable a meaningful processing of all the features, we need to encode and scale them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\"race\", \"sex\", \"age\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "numericaldata = dataset[numerical_features]\n",
    "target = 'income'\n",
    "targetdata = dataset[target]\n",
    "\n",
    "# binary encoding for female (0) and male (1)\n",
    "sex_mapping = {' Female': 0, ' Male': 1}\n",
    "numericaldata.loc[:, \"sex\"] = numericaldata[\"sex\"].replace(sex_mapping)\n",
    "\n",
    "# for simplicity we differentiate between white (0) and \"others\" (1)\n",
    "race_mapping = {' White': 0, ' Black': 1, ' Asian-Pac-Islander': 1, ' Amer-Indian-Eskimo': 1, ' Other': 1}\n",
    "numericaldata.loc[:, \"race\"] = numericaldata[\"race\"].replace(race_mapping)\n",
    "\n",
    "# minmax because we can not assume standard distribution for our numerical features\n",
    "scaler = MinMaxScaler()\n",
    "numericaldata_scaled = scaler.fit_transform(numericaldata)\n",
    "\n",
    "# income should not be transformed as it is the target variable\n",
    "target_mapping = {' <=50K': 0, ' >50K': 1}\n",
    "targetdata = targetdata.replace(target_mapping)\n",
    "\n",
    "# the result is a NumPy-Array, so let's convert it back into a DataFrame\n",
    "numericaldata = pd.DataFrame(numericaldata_scaled, columns=numericaldata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"workclass\", \"marital-status\", \"occupation\", \"native-country\"]\n",
    "\n",
    "categoricaldata = dataset[categorical_features]\n",
    "\n",
    "# one-hot encoding for categorical features\n",
    "data, columns = lib.OneHotEncoder(categoricaldata, categorical_features)\n",
    "\n",
    "# merge data\n",
    "combined_data = pd.concat((numericaldata, data, targetdata), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitive Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">TASK 1: Do you want to include or exclude sensitive features for the training later on? You can choose to treat them with a special careful focus or remove them entirely.</span>\n",
    "* `sex`\n",
    "* `age`\n",
    "* `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which (potentially) sensitive features do you want to focus on explicitly?\n",
    "selected_sensitive_features = [\"race\", \"sex\", \"age\"]\n",
    "\n",
    "# Do you want to remove any sensitive features?\n",
    "remove = []\n",
    "\n",
    "# remove selected sensitive features and create a separate decoded dataframe for the sensitive features (required later on)\n",
    "dataset, sensitive_data = lib.remove_sensitive_features(combined_data, remove, selected_sensitive_features, features)\n",
    "\n",
    "display(dataset.head())\n",
    "display(sensitive_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\"> TASK 2: Take a look at the correlations with sensitive attributes. What implications could this have for fairness? If you have removed some sensitive features, would you like to remove correlated features as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix for all features\n",
    "correlation_matrix = combined_data.corr()\n",
    "correlation_threshold = 0.1 # set threshold for minimum correlation with sensitive attributes\n",
    "\n",
    "# leave out uncorrelated features below threshold for overview\n",
    "for feature in selected_sensitive_features:\n",
    "    correlation = correlation_matrix[feature].abs() > correlation_threshold\n",
    "    correlation_subset = correlation_matrix.loc[correlation, correlation]\n",
    "\n",
    "# plot reduced correlation matrix\n",
    "    sns.set(style=\"white\")\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(correlation_subset, ax=plt.gca(), cmap=\"coolwarm\", fmt=\".2f\", square=True)\n",
    "    plt.title(f\"Correlation Matrix (Features with correlation > {correlation_threshold} for {feature})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "To reduce our feature space to a manageable size, we need to select the most relevant features. `Lasso (Least Absolute Shrinkage and Selection Operator)` is a regression method that attempts to reduce the number of features used in a model by setting some of the coefficients to zero. Features whose coefficients have been reduced to zero are not included in the model. In addition to ordinary linear regression, it adds a cost function (loss function) that is to be minimized. The **alpha value** stands for the regularization strength, which controls the effects of the regularization on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the feature selection strategy\n",
    "selection_strategy = 'Lasso'\n",
    "\n",
    "alpha = 0.01               # needed for Lasso regression\n",
    "n_features = 5             # needed for PCA: number of features\n",
    "\n",
    "# make sure the sensitive features remain in the features\n",
    "ready_data = lib.select_the_features(combined_data, selection_strategy, alpha, n_features, target, selected_sensitive_features)\n",
    "# check whether our preprocessed data are ready for training\n",
    "ready_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and target features\n",
    "X = ready_data.drop(target, axis=1)\n",
    "Y = ready_data[target]\n",
    "\n",
    "# train, test split. \n",
    "# an additional split is performed for A_train and A_test wich include the sensitive attributes, which will be required later on)\n",
    "X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(X, Y, sensitive_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">TASK 3: Which training algorithm do you want to use? How do you want to weight classes (we will return to this after the first evaluation)?</span>\n",
    "\n",
    "* `Linear Regression` classifies indviduals based on a probability threshold. Features are additive and directly interpretable.\n",
    "\n",
    "* `Decision Trees` partition the dataset into subgroups and create rules for each node based on the characteristics. For a small number of nodes, decision trees are intuitively interpretable.\n",
    "\n",
    "* `Random Forest` is an ensemble method based on decision trees. It creates a large number of decision trees and combines their predictions to achieve more robust and accurate regression results. However, interpretation is more difficult and imprecise.\n",
    "\n",
    "* `MLP Classifiers` are basically artificial neural networks and super powerful in learning non-linear relationships. However, we need to rely on model-agnostic XAI tools like LIME to approximate feature importance. Also, in our use case it is not possible to apply unfairness mitigation on MLP Classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "Choose one model for training and specify the parameters. Ignore the rest of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Linear Regression\"\n",
    "\n",
    "class_weight = {\n",
    "    0:1/6, # weight for negative class (<= 50K)\n",
    "    1:5/6} # weight for positive class (>50K)\n",
    "lr = RidgeClassifier(alpha=0, class_weight=class_weight).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Decision Tree\"\n",
    "\n",
    "max_depth = 10 # maximum level of decision nodes, the higher the more complex (but also the more prone to overfitting)\n",
    "class_weight = {\n",
    "    0:1/6, # weight for negative class (<= 50K)\n",
    "    1:5/6} # weight for positive class (>50K)\n",
    "dt = DecisionTreeClassifier(max_depth=max_depth, class_weight=class_weight).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Random Forest\"\n",
    "\n",
    "n_estimators = 100 # number of decision trees used for the ensemble classifer\n",
    "max_depth = 10 # maximum level of decision nodes, the higher the more complex (but also the more prone to overfitting)\n",
    "class_weight = {\n",
    "    0:1/6, # weight for negative class (<= 50K)\n",
    "    1:5/6} # weight for positive class (>50K)\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight=class_weight).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"MLP Classifier\"\n",
    "\n",
    "hidden_layer_sizes = 10 # the number of hidden layers represents the complexity of your ANN: from 1 (simple) to 100 (complex)\n",
    "max_iter = 200 # manual stopping criteria to accelerate training or prevent overfitting\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select your model\n",
    "selected_model = rf\n",
    "\n",
    "Y_pred = selected_model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "Now that we have obtained our predictions, it is time to critically evaluate our performance. As you now, there is a broad range of performance metrics:\n",
    "\n",
    "* `Confusion Matrix` is a tabular representation of the true and predicted classifications. It enables a detailed analysis of the model performance.\n",
    "\n",
    "* `Accuracy` measures the percentage of correct predictions in relation to the total number of predictions.\n",
    "\n",
    "* `Precision` measures the percentage of true positive predictions (TP) in relation to all positive classifications (TP + FP). It is particularly important in situations where overestimated labels (false positives) are costly.\n",
    "\n",
    "* `Recall` measures the percentage of true positive predictions (TP) in relation to all true instances (TP+FN). It is particularly important in situations where underestimated labels (false negatives) are costly.\n",
    "\n",
    "* `F-Beta-Score` provides a balance between precision and recall, where Beta specifies the ratio of recall importance to precision importance. For beta = 1, precision and recall are weighted equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">TASK 4: How do you evaluate your model's performance? Are there any improvements required?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "img = Image.open(\"img\\confusion_matrix.png\")\n",
    "display(img, )\n",
    "class_labels = [\"<=50K\", \">50K\"]\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "heatmap = sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', annot_kws={\"size\": 12}, xticklabels=class_labels, yticklabels=class_labels)\n",
    "heatmap.set_xlabel(\"Predicted label\")\n",
    "heatmap.set_ylabel(\"True label\")\n",
    "plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "plt.show()\n",
    "\n",
    "# accuracy, precision, recall\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred, average='macro'))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred, average='macro')) \n",
    "\n",
    "# f-beta-score (a higher beta gives more weight to recall)\n",
    "beta = 1\n",
    "print(f\"F-{beta}-Score:\", fbeta_score(Y_test, Y_pred, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">TASK 5: How do you evaluate your model's reasoning? Are there any improvements required?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Feature importance should always be interpreted with caution because it can be imprecise and does not tell us *how* the features are used. However, it can give us a broad indication of how the model comes to its conclusions.\n",
    "* `Linear Regression`: Feature importance can be directly obtained from the **coefficients**. Remember that our feature encoding was 0 for white (vs. 1 for others) and 0 for women (vs. 1 for men)\n",
    "* `Decision Tree` and `Random Forest`: Feature importance is measured by the amount of reduction in the Gini **impurity** (see decision tree above). However, this only includes absolute values and does not give an indication about the features \"direction\".\n",
    "* `MLP Classifier`: due to the blackbox behavior of ANNs, we need to rely on **LIME** to provide local feature importance (of selected individuals). In this case, the feauture importance refers to a random instance. Feature and Value describe the individual's feature values. Prediction probabilities specify the classification certainty. The bar chart approximates each feature's contribution to the classification outcome. Run the method a few times to get an intuition for LIME explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "lib.feature_importance(selected_model, X_train, X_test, selected_sensitive_features, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Decision trees can have meaningful decision rules that humans are able to interpret. However, it is not always too intuitive. Here are some explanations for the lines of each box:\n",
    "* **First line**: decision rule with feature name and feature threshold\n",
    "* **Second line**: Gini scores quantify the purity of a node, i.e., how dispersely the samples are distributed. The purer the node the darker the color.\n",
    "* **Third line**: samples show the proportion of total samples handled in the current node\n",
    "* **Fourth line**: distribution of how many samples fall into each class (left value refers to <=50K, the right value to >50K)\n",
    "* **Fifth line**: majority class of the samples handled in the current node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "if selected_model == dt:    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    plot_tree(dt, feature_names = features, class_names = class_labels, max_depth=3, fontsize=9, proportion=True, filled=True, rounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness\n",
    "You learned that performance is not the only criterion to evaluate. For example, high accuracy can still introduce imbalanced effects for demographic groups. Below is a list of available group fairness metrics that you can select from:\n",
    "\n",
    "- `accuracy` compares the model's accuracy between sensitive groups\n",
    "- `selection_rate` compares the rate of positively classified samples (corresponds to **demographic parity**)\n",
    "- `true positive rate`: difference between true positive rates (corresponds to **equality of opportunity**)\n",
    "- `false positive rate`: difference between false positive rates (in combination with the true positive rate this corresponds to **equalized odds**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">TASK 6: How do you evaluate your model's fairness? How does it compare to your colleagues' models? Are there any interventions required?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the fairness metrics you want to evaluate\n",
    "fairness_metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"selection_rate\": flm.selection_rate,\n",
    "    \"false_positive_rate\": flm.false_positive_rate,\n",
    "    \"false_negative_rate\": flm.false_negative_rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fairness evaluation\n",
    "for feature in selected_sensitive_features:\n",
    "    \n",
    "    metricframe_unmitigated = flm.MetricFrame(\n",
    "        metrics=fairness_metrics,\n",
    "        y_true=Y_test,\n",
    "        y_pred=Y_pred,\n",
    "        sensitive_features=A_test[feature],\n",
    "        )\n",
    "\n",
    "    print(f\"Differences for feature {feature}:\\n {metricframe_unmitigated.difference()}\")\n",
    "\n",
    "    metricframe_unmitigated.by_group.plot.bar(\n",
    "        subplots=True,\n",
    "        sharey = all,\n",
    "        title=(f\"Group disparities for feature {feature}\"), \n",
    "        layout=[1, len(fairness_metrics)], \n",
    "        figsize=[20, 4], \n",
    "        legend=None\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfairness Mitigation\n",
    "\n",
    "* **Balancing imbalanced data**: By oversampling underrepresented instances (e.g., black women), we can artificially increase the representation of underrepresented classes. Ideally, we should collect more data of underrepresented classes in order to improve performance for them.\n",
    "\n",
    "* **Removing correlations with sensitive attributes**: If we want to nullify any influence of sensitive attributes, we should not only remove them from our data. Instead, we need to also account for correlations.\n",
    "\n",
    "* **Penalty terms or regularization**: Introducing penalty terms or regularization for unwanted behavior (e.g, use of sensitive attributes) during the training process can guide models to pay particular attention to performance on the underrepresented class.\n",
    "\n",
    "* **Optimizing for fairness metrics**: With the Fairlearn library we can optimize our classifiers to adhere to specified fairness metrics. However, due to the \"impossibility of fairness\" we need to make a judgement call about which metric to optimize.\n",
    "\n",
    "* **Overruling decisions**: In human-AI hybrid settings, human experts can manually overrule a model's classification. They can account for contextual factors that are not captured in the data.\n",
    "\n",
    "Since we are limited to simple programming, we will use the Fairlearn package to optimize a specified fairness metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">TASK 7: How do you want to improve fairness? Which fairness metric do you want to optimize? How do the classifications change?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing for Fairness Metrics\n",
    "Due to technical constraints, only `Linear Regression`, `DecisionTree` and `RandomForest` models can be enhanced with Fairlearn mitigations. Of course, you can also argue that optimizing for accuracy is the way to go anayways, which makes this section obsolete.\n",
    "- `accuracy_score`: regular accuracy score\n",
    "- `balanced_accuracy_score`: equal accuracy for all sensitive groups\n",
    "- `demographic_parity` equalizes the rate of positively classified samples\n",
    "- `true_positive_rate_parity`: equalizes true positive rates (corresponds to **equality of opportunity**)\n",
    "- `false_positive_rate_parity`: equalizes false positive rates (in combination with the true positive rate this corresponds to **equalized odds**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the primary training objective (\"accuracy_score\", \"balanced_accuracy_score\", \"selection_rate\", \"true_positive_rate\", \"true_negative_rate\")\n",
    "primary_objective = \"balanced_accuracy_score\"\n",
    "\n",
    "# select the equality metric you want to use as a constraint (\"demographic_parity\", \"true_positive_rate_parity\", \"false_negative_rate_parity\")\n",
    "fairness_metric = \"true_positive_rate_parity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train reconfigured model (only for lr, dt, and rf)\n",
    "mitigated_model = ThresholdOptimizer(estimator=selected_model, constraints=fairness_metric, objective=primary_objective)\n",
    "mitigated_model.fit(X_train, Y_train, sensitive_features=A_train)\n",
    "Y_pred_mitigated = mitigated_model.predict(X_test, sensitive_features=A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fairness evaluation for reconfigured model (only for lr, dt, and rf)\n",
    "for feature in selected_sensitive_features:\n",
    "\n",
    "    metricframe_mitigated = flm.MetricFrame(\n",
    "        metrics=fairness_metrics,\n",
    "        y_true=Y_test,\n",
    "        y_pred=Y_pred_mitigated,\n",
    "        sensitive_features=A_test[feature],\n",
    "        )\n",
    "\n",
    "    print(f\"Differences for feature {feature}:\\n {metricframe_mitigated.difference()}\")\n",
    "\n",
    "    metricframe_mitigated.by_group.plot.bar(\n",
    "        subplots=True,\n",
    "        sharey = all,\n",
    "        title=(f\"Group disparities for feature {feature}\"), \n",
    "        layout=[1, len(fairness_metrics)], \n",
    "        figsize=[20, 4], \n",
    "        legend=None\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "Finally, it is time to put your model into practice. Or is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">TASK 8: Would you deploy your model in practice? If not, what would be required to do so? Would you maybe choose an entirely different approach to solve the use case?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
